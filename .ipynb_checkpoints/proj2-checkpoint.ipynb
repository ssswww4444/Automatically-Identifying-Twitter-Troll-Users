{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/peiyuns/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download(\"stopwords\")\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorizer\n",
    "vec = DictVectorizer()\n",
    "\n",
    "# Get array of dictionary according to the list of tweets \n",
    "def getDict(tweets):\n",
    "    dict_arr = []\n",
    "    for tweet in tweets:\n",
    "        tweet_dict = {}\n",
    "        for word in tweet:\n",
    "            if word in tweet_dict:\n",
    "                tweet_dict[word] += 1\n",
    "            else:\n",
    "                tweet_dict[word] = 1\n",
    "        dict_arr.append(tweet_dict)\n",
    "    return dict_arr\n",
    "\n",
    "# Hyperparameter sets\n",
    "alphas = [0.001, 0.01, 0.1, 1, 10, 100]\n",
    "penaltys = ['l1', 'l2']\n",
    "Cs = [0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
    "\n",
    "# Init best hyperparameters\n",
    "best_bayes_params = {}\n",
    "best_bayes_score = 0\n",
    "best_logistic_params = {}\n",
    "best_logistic_score = 0\n",
    "\n",
    "print \"Naive Bayes hyperparameters:\"\n",
    "# Tune naive bayes hyperparameters\n",
    "for alpha in alphas:\n",
    "    bayes = MultinomialNB(alpha = alpha) # Create classifier\n",
    "    bayes.fit(X_training, y_training) # Train model\n",
    "    score = bayes.score(X_develop, y_develop) # Calculate score \n",
    "    print (\"alpha = %7.3f, Score = %.4f\" % (alpha, score)) # Print result\n",
    "    \n",
    "    # Check if better\n",
    "    if score > best_bayes_score:\n",
    "        best_bayes_params = {'alpha':alpha}\n",
    "        best_bayes_score = score\n",
    "\n",
    "print \"\"\n",
    "print \"Logistic Regression hyperparameters\"\n",
    "# Tune logistic regression hyperparameters\n",
    "for C in Cs:\n",
    "    for penalty in penaltys:\n",
    "        logistic = LogisticRegression(C = C, penalty = penalty) # Create classifier\n",
    "        logistic.fit(X_training, y_training) # Train model\n",
    "        score = logistic.score(X_develop, y_develop) # Calculate score  \n",
    "        print(\"penalty = %s, C = %8.3f, Score = %.4f\" % (penalty, C, score))\n",
    "    \n",
    "        # Check if better\n",
    "        if score > best_logistic_score:\n",
    "            best_logistic_params = {'C':C, 'penalty':penalty}\n",
    "            best_logistic_score = score\n",
    "        \n",
    "print \"\"\n",
    "print (\"Naive Bayes: best parameter: %s, score = %f\" % (str(best_bayes_params), best_bayes_score))\n",
    "print (\"Logistic Regression: best parameter: %s, score = %f\" % (str(best_logistic_params), best_logistic_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classifiers\n",
    "bayes_clf = MultinomialNB(alpha = best_bayes_params['alpha'])\n",
    "logistic_clf = LogisticRegression(C = best_logistic_params['C'], penalty = best_logistic_params['penalty'])\n",
    "\n",
    "# Train classifiers\n",
    "bayes_clf.fit(X_training, y_training)\n",
    "logistic_clf.fit(X_training, y_training)\n",
    "\n",
    "print (\"Naive Bayes: f-score = %.4f, accuracy = %.4f\" % (f1_score(bayes_clf.predict(X_test),y_test, average = 'macro'), accuracy_score(bayes_clf.predict(X_test),y_test)))\n",
    "print (\"Logistic Regression: f-score = %.4f, accuracy = %.4f\" % (f1_score(logistic_clf.predict(X_test),y_test, average = 'macro'), accuracy_score(logistic_clf.predict(X_test),y_test)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
